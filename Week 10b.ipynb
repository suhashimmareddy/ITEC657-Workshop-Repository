{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes' theorem with the \"naive\" assumption of conditional independence between every pair of features given the value of the class variable. Bayes'theorem states the following relationship, given class variable $y$ and dependent feature vector $x_1$ through $x_n$,:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the naive conditional independence assumption, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use Maximum A Posteriori (MAP) estimation to estimate $P(y)$ and $P(x_i \\mid y)$; the former is then the relative frequency of class $y$ in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*:\n",
    "H. Zhang (2004). The optimality of Naive Bayes. Proc. FLAIRS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB implements the Gaussian Naive Bayes algorithm for classification.   \n",
    "The likelihood of the features is assumed to be Gaussian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\sigma_y$ and $\\mu_y$  are estimated using maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** - The training data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1]\n",
      " [-2 -1]\n",
      " [-3 -2]\n",
      " [ 1  1]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n",
      "[1 1 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Training a GaussianNB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[Code...]\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[-0.8, -1]]))\n",
    "print(clf.predict([[4, 5]]))\n",
    "print(clf.predict([[10, -5]]))\n",
    "print(clf.predict([[2, -5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*   \n",
    "C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** - The training data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 2 0 2 1 2 3 0 2 2 0 4 0 4 1 4 1 0 4 3 4 2 1 2 0 3 1 3 1 4 3 2 3 2 0\n",
      "  2 0 2 1 4 4 3 3 3 0 0 0 4 4 1 0 4 1 3 0 3 0 1 3 4 1 2 4 2 0 3 0 2 4 3 2\n",
      "  1 2 0 4 3 4 3 4 4 3 0 2 3 4 1 0 0 2 4 4 3 0 0 1 2 3 3 2]\n",
      " [3 3 3 4 1 2 3 0 0 1 1 3 0 1 4 3 3 4 0 4 0 2 3 2 1 3 2 2 2 2 3 0 4 1 4 0\n",
      "  0 0 4 1 2 1 3 3 4 0 1 0 3 4 4 1 3 4 3 1 2 3 0 0 2 0 0 4 4 3 0 1 3 3 0 1\n",
      "  4 2 4 0 3 1 3 1 1 4 3 1 3 2 2 4 3 1 0 1 3 1 2 3 2 0 1 2]\n",
      " [0 3 3 0 2 4 2 2 4 1 1 3 2 0 2 4 1 1 3 2 1 0 4 2 3 0 3 2 3 2 2 2 2 3 3 2\n",
      "  4 1 0 3 4 4 2 2 0 2 3 4 1 4 4 0 3 2 3 3 2 1 1 0 4 1 0 4 2 1 2 2 2 0 1 4\n",
      "  1 2 4 1 4 2 4 1 3 0 1 2 1 3 0 4 0 1 0 0 4 4 4 1 0 4 3 1]\n",
      " [3 3 1 0 2 0 0 2 1 4 2 0 2 0 1 1 1 0 1 4 4 2 1 4 4 2 1 2 1 3 3 4 4 4 3 3\n",
      "  3 4 4 4 3 1 2 3 3 0 1 4 4 3 1 0 1 2 1 2 0 1 1 2 4 3 0 0 0 1 4 3 3 0 4 4\n",
      "  2 2 1 2 2 1 4 2 4 3 3 3 4 4 1 1 0 3 4 1 3 3 0 4 4 2 0 3]\n",
      " [0 2 0 3 4 2 2 3 4 1 1 0 4 0 4 0 1 0 3 0 4 0 1 0 3 3 1 0 4 4 1 3 0 3 0 3\n",
      "  1 1 2 4 1 0 0 3 0 0 4 0 1 2 0 1 4 2 2 1 1 2 0 3 3 1 1 0 2 3 3 4 1 3 3 0\n",
      "  3 4 4 3 4 3 4 4 4 3 0 4 2 3 4 4 2 3 3 4 2 1 3 1 4 1 0 2]\n",
      " [1 1 0 4 1 2 2 1 4 0 4 4 1 3 1 4 0 0 1 1 2 1 3 4 0 2 3 3 2 1 2 2 4 4 1 1\n",
      "  3 2 3 1 0 4 4 2 4 4 3 0 4 0 0 4 0 3 1 4 4 4 4 2 1 1 2 0 0 1 2 4 0 0 2 0\n",
      "  2 4 0 2 4 3 0 3 2 1 1 1 4 0 4 0 4 4 2 0 0 3 4 2 0 0 0 0]]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(5, size=(6, 100))\n",
    "print(X)\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: Training a MultinomialNB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[Code...]\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4 5]\n",
      "[2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X[2:3]))\n",
    "print(clf.predict(X[3:5]))\n",
    "print(clf.predict(X[1:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Process on 'Iris' Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Week 9, we have studied how to use KNN algorithm to do classification task on 'iris' data. Here,we are going to employ the GaussianNB to conduct the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_dataset = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "iris_dataset['data'], iris_dataset['target'], random_state=142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**ï¼šReport the acuracy result on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[Code...]\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821428571428571"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "np.mean(y_train == y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 15,  2],\n",
       "       [ 0,  2, 12]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0],\n",
       "       [ 0, 32,  1],\n",
       "       [ 0,  1, 35]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Predict Human Activity Recognition (HAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this practice exercise is to predict current human activity based on phisiological activity measurements from 53 different features based in the [HAR dataset](http://groupware.les.inf.puc-rio.br/har#sbia_paper_section). The training (`har_train.csv`) and test (`har_validate.csv`) datasets are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**: Build a Naive Bayes model, predict on the test dataset and compute the [confusion matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62). Note: Please refer to the [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13737, 53)\n",
      "(5885, 53)\n"
     ]
    }
   ],
   "source": [
    "#[Code...]\n",
    "import pandas as pd\n",
    "x = pd.read_csv(\"har_train.csv\")\n",
    "y = pd.read_csv(\"har_validate.csv\")\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['classe', 'roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt',\n",
       "       'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x',\n",
       "       'accel_belt_y', 'accel_belt_z', 'magnet_belt_x', 'magnet_belt_y',\n",
       "       'magnet_belt_z', 'roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm',\n",
       "       'gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z', 'accel_arm_x',\n",
       "       'accel_arm_y', 'accel_arm_z', 'magnet_arm_x', 'magnet_arm_y',\n",
       "       'magnet_arm_z', 'roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell',\n",
       "       'total_accel_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y',\n",
       "       'gyros_dumbbell_z', 'accel_dumbbell_x', 'accel_dumbbell_y',\n",
       "       'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y',\n",
       "       'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm',\n",
       "       'total_accel_forearm', 'gyros_forearm_x', 'gyros_forearm_y',\n",
       "       'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y',\n",
       "       'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y',\n",
       "       'magnet_forearm_z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['classe', 'roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt',\n",
       "       'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x',\n",
       "       'accel_belt_y', 'accel_belt_z', 'magnet_belt_x', 'magnet_belt_y',\n",
       "       'magnet_belt_z', 'roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm',\n",
       "       'gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z', 'accel_arm_x',\n",
       "       'accel_arm_y', 'accel_arm_z', 'magnet_arm_x', 'magnet_arm_y',\n",
       "       'magnet_arm_z', 'roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell',\n",
       "       'total_accel_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y',\n",
       "       'gyros_dumbbell_z', 'accel_dumbbell_x', 'accel_dumbbell_y',\n",
       "       'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y',\n",
       "       'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm',\n",
       "       'total_accel_forearm', 'gyros_forearm_x', 'gyros_forearm_y',\n",
       "       'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y',\n",
       "       'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y',\n",
       "       'magnet_forearm_z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classe  roll_belt  pitch_belt  yaw_belt  total_accel_belt  gyros_belt_x  \\\n",
      "0      A       1.41        8.07     -94.4                 3          0.00   \n",
      "1      A       1.41        8.07     -94.4                 3          0.02   \n",
      "2      A       1.42        8.07     -94.4                 3          0.00   \n",
      "3      A       1.48        8.05     -94.4                 3          0.02   \n",
      "4      A       1.45        8.06     -94.4                 3          0.02   \n",
      "\n",
      "   gyros_belt_y  gyros_belt_z  accel_belt_x  accel_belt_y  ...  \\\n",
      "0           0.0         -0.02           -21             4  ...   \n",
      "1           0.0         -0.02           -22             4  ...   \n",
      "2           0.0         -0.02           -20             5  ...   \n",
      "3           0.0         -0.03           -22             3  ...   \n",
      "4           0.0         -0.02           -21             4  ...   \n",
      "\n",
      "   total_accel_forearm  gyros_forearm_x  gyros_forearm_y  gyros_forearm_z  \\\n",
      "0                   36             0.03             0.00            -0.02   \n",
      "1                   36             0.02             0.00            -0.02   \n",
      "2                   36             0.03            -0.02             0.00   \n",
      "3                   36             0.02            -0.02             0.00   \n",
      "4                   36             0.02            -0.02            -0.03   \n",
      "\n",
      "   accel_forearm_x  accel_forearm_y  accel_forearm_z  magnet_forearm_x  \\\n",
      "0              192              203             -215               -17   \n",
      "1              192              203             -216               -18   \n",
      "2              196              204             -213               -18   \n",
      "3              189              206             -214               -16   \n",
      "4              193              203             -215                -9   \n",
      "\n",
      "   magnet_forearm_y  magnet_forearm_z  \n",
      "0               654               476  \n",
      "1               661               473  \n",
      "2               658               469  \n",
      "3               658               469  \n",
      "4               660               478  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13737, 52)\n",
      "(13737,)\n",
      "(5885, 52)\n",
      "(5885,)\n"
     ]
    }
   ],
   "source": [
    "X_train = x.drop(['classe'], axis =1)\n",
    "y_train = x['classe']\n",
    "X_test = y.drop(['classe'], axis = 1)\n",
    "y_test = y['classe']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542905692438402\n",
      "0.5580548882579893\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(np.mean(y_test == y_pred))\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(np.mean(y_train == y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1070,   95,  262,  212,   35],\n",
       "       [ 127,  685,  145,   76,  106],\n",
       "       [ 223,  106,  512,  136,   49],\n",
       "       [ 102,   35,  271,  441,  115],\n",
       "       [  51,  239,   95,  143,  554]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2491,  164,  667,  502,   82],\n",
       "       [ 306, 1608,  358,  191,  195],\n",
       "       [ 519,  252, 1197,  309,  119],\n",
       "       [ 240,   70,  603, 1075,  264],\n",
       "       [ 143,  518,  252,  317, 1295]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097706032285472\n",
      "0.9552303996505788\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(np.mean(y_test == y_pred))\n",
    "y_train_pred = knn.predict(X_train)\n",
    "print(np.mean(y_train == y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9575191163976211\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(np.mean(y_test == y_pred))\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(np.mean(y_train == y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27850467289719627\n",
      "0.28135691926912715\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(np.mean(y_test == y_pred))\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(np.mean(y_train == y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827017841971113\n",
      "0.8270364708451627\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(np.mean(y_test == y_pred))\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(np.mean(y_train == y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
